{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9269c9a",
   "metadata": {},
   "source": [
    "## Web scraping for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1cf7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52f83fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6971267875384e2cba7a4341e1c6e70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250\n"
     ]
    }
   ],
   "source": [
    "Url = 'https://www.imdb.com/chart/top/'\n",
    "Headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "res = requests.get(url = Url, headers = Headers)\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "#print(soup.prettify)\n",
    "body = soup.find('tbody',attrs = {'class' : 'lister-list'})\n",
    "#print(body.text)\n",
    "title = body.findAll('a')\n",
    "year = body.findAll('span',attrs = {'class' : 'secondaryInfo'})\n",
    "years = [i.text.lstrip('(').rstrip(')') for i in year]\n",
    "rating = body.findAll('td',attrs = {'class' : 'ratingColumn imdbRating'})\n",
    "ratings = [i.text.strip('\\n') for i in rating]\n",
    "titles = []\n",
    "links = []\n",
    "movie_id = []\n",
    "for i in tqdm(title):\n",
    "    if(i.text != ' \\n'):\n",
    "        titles.append(i.text)\n",
    "    for j in str(i):\n",
    "        if(j == '?'):\n",
    "            l = str(i).index(j)\n",
    "            break\n",
    "    s = str(i)[9:l]\n",
    "    if s not in movie_id:\n",
    "        movie_id.append(s)\n",
    "    li = 'https://www.imdb.com'+s+'reviews?ref_=tt_urv'\n",
    "    if( li not in links):\n",
    "        links.append(li)\n",
    "print(len(movie_id),len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213b126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Title' : titles,\n",
    "    'Link' : links,\n",
    "    'Year' : years,\n",
    "    'Rating' : ratings,\n",
    "    'Movie_ID' : movie_id\n",
    "}\n",
    "file = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cec074",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_csv('C:/Users/joshy/Desktop/project/0_input/input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf950b6",
   "metadata": {},
   "source": [
    "### Function to remove the files in a directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a28b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dir(direc):\n",
    "    import os, shutil\n",
    "    folder = direc\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1f791",
   "metadata": {},
   "source": [
    "### Function for eliminating emojis and unwanted characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c298b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import unidecode\n",
    "\n",
    "# https://stackoverflow.com/a/49146722/330558\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e5bd0",
   "metadata": {},
   "source": [
    "## Function for Web scraping and writing article data into text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aed1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracter(url,id):\n",
    "    URL = url\n",
    "    id = id.replace(\":\",\"\")\n",
    "    print(id)\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "    # Here the user agent is for Edge browser on windows 10. You can find your browser user agent from the above given link.\n",
    "    r = requests.get(url=URL, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser') # If this line causes an error, run 'pip install html5lib' or install html5lib\n",
    "    title = [i.text for i in soup.find_all('a', attrs = {'class' : 'title'})]\n",
    "    review = [i.text for i in soup.find_all('div', attrs = {'class':'text show-more__control'})]\n",
    "    user = [i.text.replace(\"*\",\"\") for i in soup.find_all('span', attrs = {'class' : 'display-name-link'})]\n",
    "    # Directory\n",
    "    directory = id\n",
    "    # Parent Directory path\n",
    "    parent_dir = \"C:/Users/joshy/Desktop/project/2_data\"\n",
    "    # Path\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    # Create the directory\n",
    "    if id not in os.listdir(parent_dir):\n",
    "        os.mkdir(path)\n",
    "    else:\n",
    "        path\n",
    "        \n",
    "    for i in range(len(title)):\n",
    "        title[i] = remove_emoji(title[i]) \n",
    "        title[i] = unidecode.unidecode(title[i])\n",
    "        with open(f'{parent_dir}/{id}/{user[i]}.txt', 'a') as f:\n",
    "            f.write(title[i])\n",
    "            f.write('\\n')\n",
    "        \n",
    "    for i in range(len(title)):\n",
    "        review[i] = remove_emoji(review[i])\n",
    "        review[i] = unidecode.unidecode(review[i])\n",
    "        with open(f'{parent_dir}/{id}/{user[i]}.txt', 'a') as f:\n",
    "            f.write(review[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b55feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/joshy/Desktop/project/2_data\"\n",
    "#remove_dir(path)\n",
    "dir = os.listdir(path)\n",
    "if(len(dir) > 0 and len(dir) < len(links)):\n",
    "    for i in tqdm(range(len(dir)-1,len(links))):\n",
    "        url = links[i]\n",
    "        id = titles[i]\n",
    "        extracter(url,id)\n",
    "elif(len(dir) == len(links)):\n",
    "    pass\n",
    "else:\n",
    "    for i in tqdm(range(len(dir),len(links))):\n",
    "        url = links[i]\n",
    "        id = titles[i]\n",
    "        extracter(url,id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca92d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568368a7",
   "metadata": {},
   "source": [
    "git clone https://github.com/laxmimerit/IMDB-Movie-Reviews-Large-Dataset-50k.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "abf20652",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_excel(r'C:\\Users\\joshy\\Desktop\\project\\IMDB-Movie-Reviews-Large-Dataset-50k\\train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a6b82dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I first tuned in on this morning news, I ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mere thoughts of \"Going Overboard\" (aka \"Babes...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does this movie fall WELL below standards?...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow and I thought that any Steven Segal movie ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The story is seen before, but that does'n matt...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  When I first tuned in on this morning news, I ...       neg\n",
       "1  Mere thoughts of \"Going Overboard\" (aka \"Babes...       neg\n",
       "2  Why does this movie fall WELL below standards?...       neg\n",
       "3  Wow and I thought that any Steven Segal movie ...       neg\n",
       "4  The story is seen before, but that does'n matt...       neg"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b89d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "for i in file['Sentiment']:\n",
    "  if i == 'pos':\n",
    "    rating.append(1)\n",
    "  elif i == 'neg':\n",
    "    rating.append(-1)\n",
    "  else:\n",
    "    rating.append(0)\n",
    "file['Rating'] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "66b1fb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I first tuned in on this morning news, I ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mere thoughts of \"Going Overboard\" (aka \"Babes...</td>\n",
       "      <td>neg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does this movie fall WELL below standards?...</td>\n",
       "      <td>neg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow and I thought that any Steven Segal movie ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The story is seen before, but that does'n matt...</td>\n",
       "      <td>neg</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment  Rating\n",
       "0  When I first tuned in on this morning news, I ...       neg      -1\n",
       "1  Mere thoughts of \"Going Overboard\" (aka \"Babes...       neg      -1\n",
       "2  Why does this movie fall WELL below standards?...       neg      -1\n",
       "3  Wow and I thought that any Steven Segal movie ...       neg      -1\n",
       "4  The story is seen before, but that does'n matt...       neg      -1"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d51bb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "36db9197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/laxmimerit/preprocess_kgptalkie.git\n",
      "  Cloning https://github.com/laxmimerit/preprocess_kgptalkie.git to c:\\users\\joshy\\appdata\\local\\temp\\pip-req-build-knnjlrtn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joshy\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joshy\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/laxmimerit/preprocess_kgptalkie.git 'C:\\Users\\joshy\\AppData\\Local\\Temp\\pip-req-build-knnjlrtn'\n",
      "  fatal: unable to access 'https://github.com/laxmimerit/preprocess_kgptalkie.git/': Could not resolve host: github.com\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  git clone --filter=blob:none --quiet https://github.com/laxmimerit/preprocess_kgptalkie.git 'C:\\Users\\joshy\\AppData\\Local\\Temp\\pip-req-build-knnjlrtn' did not run successfully.\n",
      "  exit code: 128\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "git clone --filter=blob:none --quiet https://github.com/laxmimerit/preprocess_kgptalkie.git 'C:\\Users\\joshy\\AppData\\Local\\Temp\\pip-req-build-knnjlrtn' did not run successfully.\n",
      "exit code: 128\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joshy\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joshy\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\joshy\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f8bd3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_kgptalkie as ps\n",
    "import re\n",
    "\n",
    "def get_clean(x):\n",
    "    x = str(x).lower().replace('\\\\', '').replace('_', ' ')\n",
    "    x = ps.cont_exp(x)\n",
    "    x = ps.remove_emails(x)\n",
    "    x = ps.remove_urls(x)\n",
    "    x = ps.remove_html_tags(x)\n",
    "    x = ps.remove_rt(x)\n",
    "    x = ps.remove_accented_chars(x)\n",
    "    x = ps.remove_special_chars(x)\n",
    "    x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3557dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshy\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file['Reviews'] = file ['Reviews'].apply(lambda x: get_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6977a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features = 5000)\n",
    "X = file['Reviews']\n",
    "y = file['Sentiment']\n",
    "\n",
    "X = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf5fcf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2845641 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "968bdfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "912a50e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c67b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce0e205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.87      0.87      0.87      2480\n",
      "         pos       0.87      0.88      0.88      2520\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62fb4edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the finest films made in recent years it is a poignant story about hope\n"
     ]
    }
   ],
   "source": [
    "x = \"One of the finest films made in recent years. It's a poignant story about hope.\"\n",
    "\n",
    "x = get_clean(x)\n",
    "print(x)\n",
    "vec = tfidf.transform([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a98a1441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25520eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d37d59",
   "metadata": {},
   "source": [
    "## Extracting Data from text file into a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "144394bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io, os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaa7130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dict = {'test' : r'C:\\Users\\joshy\\Desktop\\project\\2_data'}\n",
    "text_dict = {'test' : {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abc32399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcddb472961468fa679cbe9d788767d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, folder in folder_dict.items():\n",
    "    movies = os.listdir(folder)\n",
    "    for movie in tqdm(movies):\n",
    "        text_files = os.listdir(os.path.join(folder, movie))\n",
    "        for file in text_files:\n",
    "            with open(os.path.join(folder, movie, file), 'r') as text_file:\n",
    "                text_dict[label].setdefault(movie, []).append(' '.join(text_file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "983ea26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Deserving 10/10\\n \\n A rare 10/10 and it's deserving of such. This movie had a profound impact on me....and no better person to play it then the great Robin Williams.He acted with such emotion and intensity and vigour in each scene. It is RARE to feel like I'm inside the film, but in this case I felt like Robin Williams was constantly talking to me in this film.Alongside him, the rest of the cast did a great job.This movie was more than just acting. It represented how a person should live and enjoy life. Thank you for such a gem.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dict['test']['Dead Poets Society'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4974a248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A hymn to life\\n \\n \"Dead Poets Society\" is more than a lesson of life. It\\'s a hymn to life. It has a good message: \"Carpe diem\", which means \"Seize the day\". I completely agree with that message because there\\'s no coming back and time flies.It\\'s a reasonable movie with an inspiring story, good message, great performances from the actors, wonderful sceneries, awesome soundtrack (classical music, for example), drama and comedy.John Keating is the kind of teacher that anyone would like to have as a teacher. A teacher with such a colorful imagination and sense of humor, a teacher who inspires his students to make their dreams come true and makes their lives extraordinary. I mean, wow! John Keating is brilliantly performed by the comedian Robin Williams. In general, Robin Williams is as humorous as usual in this movie, but we can also see some of his talent for drama.Besides this incredible teacher, other great characters are: Neil Perry, Knox Overstreet, Charlie Dalton, Steven Meeks, Gerard Pitts, Todd Anderson and even Richard Cameron (although he has the power to anger us at the end because of his attitude). All of them are very well played by the actors.About the boys, Charlie Dalton aka \"Nuwanda\" is the funniest of all. He\\'s just hilarious! \"Nuwanda\" is such a funny nickname - lol.Todd Anderson is a shy character portrayed by Ethan Hawke. This actor looked so different when he was younger and his role here is completely different from (for example) \"Before Sunrise\" and \"Before Sunset\".Mr. Perry (Neil\\'s father) is a complicated character. Like Kurtwood Smith himself says, <<he\\'s understandable, not likable>>. He doesn\\'t let Neil do what he wants and controls all of his life and future.The ending is somehow... empty: Neil dies and \"Nuwanda\" is expelled. But the boys\\'s homage to Mr. Keating at the end is admirable. What\\'s even more amazing is that it is started by Todd Anderson.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dict['test']['Dead Poets Society'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fcaead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e1011ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13186f945270427898c7d7277adaa7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy_text = {}\n",
    "for movie, text_list in tqdm(text_dict['test'].items()):\n",
    "    spacy_text[movie] = list(nlp.pipe(text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "420edb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Movies':list(text_dict['test'].keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7a0485d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 Angry Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 Years a Slave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001 A Space Odyssey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 Idiots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Movies\n",
       "0          12 Angry Men\n",
       "1      12 Years a Slave\n",
       "2                  1917\n",
       "3  2001 A Space Odyssey\n",
       "4              3 Idiots"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "845dad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_no_rev(lis):\n",
    "    score = []\n",
    "    for j in tqdm(lis):\n",
    "        s = 0\n",
    "        rev = [get_clean(k) for k in j.split(\".\")]\n",
    "        for sen in rev:\n",
    "            vec = tfidf.transform([sen])\n",
    "            if(clf.predict(vec)[0] == 'pos'):\n",
    "                s += 1\n",
    "            elif(clf.predict(vec)[0] == 'neg'):\n",
    "                s -= 1\n",
    "            else:\n",
    "                continue\n",
    "        score.append(s/len(rev))\n",
    "        n_rev = len(lis)\n",
    "    return score,n_rev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6a7f4034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ed1137d4df48d1999aa6bc22089320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddd7efde19d44619c2ea95c31c1c2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshy\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d345783b8fb2451980700e82ffb8ca4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8258da0c587442d8554e5ff57f67f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb401fe3e5a4cc991e1ff3ad3d2138c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696d297f667e461191a9ff75e98a3934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6acd36e1304809b2e084d1b740d6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6dabd590584ff5b4142a0d4f9a06d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bdb63e8d9d4aee9124825dff7e2637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4611a35ded3a441a8fe180880e506f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3da523b67d74b9c91b4be0313b48754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb8f06f78b6443ca62e68da9d8c8eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05ada3f83fc4d309b99f691d9240abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a3df710e1b456aac249ed811cda356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a407fefdf34a298c85c2d3589a3aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d623b5b9783945d4887032c2a4f2d621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97af1e8b8c14f709dd4acd3fcbaf020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aceb1299a8a4b69829360bcae6164d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13674a339f34a9ca680621963aaa299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d361b14bcd3848628d4e0455b1a13d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c4ff8365e64a53bddd162391811279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8837097dd72e407ebcf80ab0b2307833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2505c6300646bea092df8c03bf6119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8124cbd3f2a1431483e4388a6db95e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a116634bcc4b0f9bdaa3278d808b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5296987355054b6dab7c0b3a042dbaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f30fe6d48a74bbcb562019b77d81afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3f51d01d424d35980e6289560366fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a005b4f30b64afc9f9b1229cec796af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182d883fe89049318bf480f7a92feb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46c0b6e129e401983844a42b1dcdff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c159bc66d849426db5da3c36fff9c8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a1db8cae66464fadbfe279184b8d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb552232226b4cb299a75f553606011b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a464d74bf91e4c7e96062474b67c38b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b60e1117375404eaceb4d3f2d1f204e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ee81a20d4b426ab66be7002a47818b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38586f94f524f56928469ba79547f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb34237f85f46688e023fdd4cf6164a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2881be2101e417683f33e593f463fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a164fdfea0f44d0874c731b33e924bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0282f0ad91554556a6ab1dec78abe540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5337f9494c4663b881f22ea901ec4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683c78be8a484630af3e2c5845d964e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a240b980cfa04b788fef633c7025838c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8b94e8b5984973841c48cb0caa6aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2b4481fa354f978170dc121dd01ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae7a26325374d1882801ada75fe109a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bfe9bd63ec45d383916ea010e786f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac9703f40a74a93bf76eb07f2923032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa20f56ff58b41648840a6ae93967b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2341517d1f6247ef98dda12a5a0b2b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f223164b5da4182814e5b58298fddee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da3d0cff54d45f5b2aaf68ae10d9701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e215d695741a4f0db399ca014803bc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47622b04471f441c9ac570f2f3a7f4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452e6380573745eb8c72fe09e2df7201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764e37554b5e4d95891d01e7d40a3324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb2a0a31b274b8285fbb259aa18756f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db2d296fae9477cba6fe04473a1e15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7228a7a27c4433a6855a8f12bfad21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692cc1eabd4d481a891e80034c0539ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6212a6d837f4bbbb50c8480c913f80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95318a8006af4cb7819b7ff5390e52d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4df2c37059d4eaab54f9a76262c63a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ed52f926a64d4b80311285b085924d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9abac9f59b40258299336640a875ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cdc2136d7d4678b5afd8455eecb30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c6e4fff5ae4c92823df2fa82e160cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbefe4f8128743a7b711e3e695f90261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea108f5de83456ebed05ddeb912c5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff841a880ae444a9ddd330022f4d04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fee5962e8984eceb2155cd9d16ca5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394d717aa3324d409d45481e2232d62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc5b4baa7e64147ad2c2e782bcc0386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63d3bc0e1d54c149eb3b768a387ed45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699ee4aac24c4aaeb876afca038e3f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d4c742122043118a73db57bf0f7339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3829af85f44b25a14486d00dabe0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e02a3148cc949ddbe9e37f25d885491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e988eb5e134720a31784434be02508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9243f0bb67749e39b233a78cf76463a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78edf8524277483a9c618a3d1e5db404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39305f9a3f124659bd6cb3e895f3e6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3319fd3bc644c8586370c0b6da02f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9466fb8c81a5495da44f2aa8f17a33c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd71ac805cf4452db0e1f9ff76983e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d14da3bcb5416586e467c9d4ffb213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6465699ae96a413eb015759f67e747d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fafc6b496c4adfa7744cc70cb3bcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ac591be6c749baa792fed9bf700636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee280f82c264b62a6a16c97eed093a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47626e3f3012413f8708e67be723d18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3380a7f9fb44a59ef7223c42854bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a097e907a049228104f1006f88d488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshy\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:404: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78634702d547411fa4f989f4361f3f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4121321e4ab848b6b31ff9a7cce40f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72d207aa5454fb396e91ee9cbab990d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01f44cdb9214599a0bccf76d40402d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3220a7a32fd14c43b91c9231248eb738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f8ffea8f3145adb4865276d418b5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9064125e619247b8835b8ac444a394dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56960e4ae3364e56a2bcb5c278c49ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf1c3b80ff54b1692b59d6876ebc776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5adf863e9d435b81f266bb255b4323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fe56e2646d46149b7602ddd4e83bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d5e73a1ab2481c97474f7b0e0bb5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130c91e2911f432b84d878a21f9c8009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33a1dce3cb1481b85336380b705392f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910afdaf68cf413aac65f4ea4356cb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac30d9831f24d869823d7c14c359c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2014303971b40a3ad5dae7e1c750295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b423bbf6f04cae885978e589c10b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27dbda8507b847048112d251b52050af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90d7ac8583846ffb2850bad8f5220d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029038bb2b9f42b3ba6937bb3cea1a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46f5f613da94d1cbd886bee97985a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fc3f4422fd42af813ba9202a5c8a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05357821b0c41f99d2ba99944999451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4748e614ef03476db88b504a250c28aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebf2172184f4156b2772339a72f2134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272b098b3fdd4267be08900c0190f944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e952d86abdb94f3087141c56ea235ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5d526d23cd4a1da87c383ecbea3296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c44b86348b46f9831f34198018f8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429eda2c59934813a9616b4a5ad16ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e067c3fadc634503b1acb1470cec04af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37abea6780eb464e8f999d3d0fce1948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89708a3bc0e84e8e8887b3e8f0751f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b8268a6f574c1bb4e1a9ec9959b72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7095bc79ed44ed968f763fdcd46dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8faeb5d3b04bce87bfc702c9160424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983e1542746c4914a990369dec326e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26c83811e594aaa96338bffb41da336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ce1577b6264637bcd8cd255229c166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2412c238b8b42949ef9a0bdc1c7849f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf0b92984ca41009cca4b832fdc2ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c15df2debf245bbb85b9491b43f05ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e266c8857ef14db9af38acdff5174969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47cc3b63eaf43b4b8b37d6c96d36145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f003ba3ff3d4ca6aaf3a7d9ff49845a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016f35de0d8447d9b36c28efac81f227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fb601bc5a4444c8aff50c581fc26fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e099711044644d1bb74f6a7b4fe1cef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x00000235CDDE9A60>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joshy\\anaconda3\\lib\\site-packages\\tqdm\\std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\joshy\\anaconda3\\lib\\site-packages\\tqdm\\notebook.py\", line 287, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077471d8f49b49a5b54e00df59aac51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5203a75502ed4e708f738ca61f17b3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dbeea7743b48f3a975122b674e0e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1aa68bc192b432d8d9ef3541eaf4101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f809421b43b4faaa6a99f07f2055630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8e359e79cc41e49f59ac1dac2474c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ff4f4db3bd4e22ad5bb5f8d7ef9b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd54d79d8934beeb6ad6a854251dacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc345516d1ac486d992655f23ac4a925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37bdc68c2a3413786007d2cbef607b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf0ef9c638e41b8a27a8c8104a37448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b430847f6dfe4e8abb49b47c44f14d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937e5d6e8dea45f3a643ce416afcca67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fd59eb048e41c6a1dc67aa22830ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7ebcf918be4fd8a94ce39c5be4c693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a26540c2e048a2b0e8bb3e0be69fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d594c19d9664f7f9260df44d3251991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059c4eb55db4412f92955a40151b91e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ee38d50dbe41d6aa6b9b328bc967a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e6bcdb34c64a52a74bcaed60afa729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56871b516164edfaf666f9646a53958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5431fd8eddca4a9b97d393014d71d65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f4c302e27742c2a478afa6ff82f906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66299ab56aa942068761df6ce62cb480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecff3c4e451c403b9e971646783a6459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8191bcf0e18c4909aedfcf9f4983dd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55b8b4974e24fa7bbb31b8aa0198830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ba7fde3fcd49738ef5c5e288adbe0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a94fc5132d24236a49a6198041fe5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e4e5b610ec41638cd8e8d4faaf82ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f476f003cd34b7bb05be1737846cd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438e72c3b2da429cb34c2b50f42073a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3b6451cb054e069147b5bffccb4941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8f8f5ce6694d3dbdacd1346652cf5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f881f7d22711405985e692c034e0f794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292db602cb54443289f75479eeae9d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2627a0479d47a19f3a8a1f8a28ab4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fceefcf608b473eb0b172cfb37b4392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250ff8c9fd6143feb6afbac1c635e308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65d615f44b145a4920fb6bbb7d389e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad047d134d0a4b1f9e3646a3b09d98d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17a33b3de0d4a26b95f32f66a8851d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c48bcc72d99419ab89965158a97708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0142bea907de435e8b740c6eb3cc354a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450fd7e217be4b42a62770d73bae73d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4995670ef9664ceeba08b7015adfccaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6ddc42f59b477c90a6cecf56443360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2967ebdfb240ad92c9b3954dbd8684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1ab3bb560b4e608981ab41d8197eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b9cbec66f14dfaacaa1a838d9f7497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f65e0c50ae437d8c3f65eb9ee4cb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c5f198160d4e6b9b5501c88a69f411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12af016ddd1f4d96bee00b1cacca18ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428f10c66707455eadf4ea888e0b638c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a9fb0f692d4ea3bc77641eb695c932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0652ab40d3c42aca83cf3fe880fece3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc70c0fd802414cb37d4d553d0dd394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bbe0f42e9841fbbaa6e9b3f92e525e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e186b04eae014cb9982bda6af5689d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edba4d2ced34e64b8e973d325532353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36238cd01716409e82837a86b4096423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e0e4d3eced4b6e8b2812a57a00a71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2a1a51ffbd4be38b04e5379afa18ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd6ad6181004336b2eabcbce37637da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29a276a088c4da8b25d87f7e49e8d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa270e7734c41c499bbf5e748075f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659fd932eb4e40988e94e53b34855fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d44245f1be45b1b1e0d3ace92d1f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703ff9df51444353888e47aaa3f22258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51947fadcec74fc3aa7b1bf97c8c6c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39db5909e4a4a048e53c5b930498f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33738f919a5b45fc990ef2693f873cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73050ec7fe241a584c93d25e09339f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f966c76e788438383d7f9601d953ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc9356d98bb4fed8501830cdaf0201b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702b5277f88649d3b7e1173720921f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a87f08cc6f4f11b871d0a00fa37dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1689d39943a543aa80ef6ba5133f0009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c5c300491f4190baf36bad2943a72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c17c741cfde401c9ad2b60cb060c31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0294b981ba4cf9ad3fb1358bd6d6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01186998a0e4cc586f846c02c46b9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444d1f832b8f4dd1b4d539aad0fc3b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8485e4ae37f04435b0b1a96ed59ee621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f383c482c11d46ce82b3b4ee55748b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cdd22a051945dba365999680fcb13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24322d7fba234c1384c9dc1eaedddbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4eee9ccf014c8d87dd9eff5f4c6cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585b58b7d10a4909adf9fb907cc37c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d952757bca4a2e89b597923b6289ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ec0108df0f4ef2af5d45e0282e4ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2781f530c304e039095baaf5f42c40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58ba39c474b47d38af3c46cba4a73d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6e84c4fdbe4c50b4f5f4ce06d551d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d577580164445a3a345684d21593c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b585c9f92cc4a9397a43d613c07072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a7893bcd034877a386f7d175afe3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8db6d7a740b433ca5723108c700ccd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa9c8c0677c42a7bb3c36ed470e276c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebec2b82019a4805982b289cfb51e5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de812600c7e48648638c12258965306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d665377551d04de386cba4bd33450f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80742c2e95449129dc48cacf906f60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cffefa464f46248ed5c6ebab7247c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16015e85445a49f48ccca619a1730a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160d01138a114d7394e5d4040138b83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63926006d5054ce1b95bda314bec53df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "no_rev  =[]\n",
    "for i in tqdm(list(text_dict['test'].keys())):\n",
    "    score,n_rev = scores_no_rev(text_dict['test'][i])\n",
    "    scores.append(sum(score))\n",
    "    no_rev.append(n_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "779f1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Scores'] = scores\n",
    "df['No.of.Reviews'] = no_rev                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cc00cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'] = df['Scores']*10/df['No.of.Reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6ca14d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>https://www.imdb.com/title/tt0050083/reviews?r...</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "      <td>/title/tt0050083/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>https://www.imdb.com/title/tt2024544/reviews?r...</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.1</td>\n",
       "      <td>/title/tt2024544/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>1917</td>\n",
       "      <td>https://www.imdb.com/title/tt8579674/reviews?r...</td>\n",
       "      <td>2019</td>\n",
       "      <td>8.2</td>\n",
       "      <td>/title/tt8579674/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>2001: A Space Odyssey</td>\n",
       "      <td>https://www.imdb.com/title/tt0062622/reviews?r...</td>\n",
       "      <td>1968</td>\n",
       "      <td>8.3</td>\n",
       "      <td>/title/tt0062622/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>https://www.imdb.com/title/tt1187043/reviews?r...</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.3</td>\n",
       "      <td>/title/tt1187043/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                  Title  \\\n",
       "4             4           12 Angry Men   \n",
       "182         182       12 Years a Slave   \n",
       "123         123                   1917   \n",
       "88           88  2001: A Space Odyssey   \n",
       "86           86               3 Idiots   \n",
       "\n",
       "                                                  Link  Year  Rating  \\\n",
       "4    https://www.imdb.com/title/tt0050083/reviews?r...  1957     8.9   \n",
       "182  https://www.imdb.com/title/tt2024544/reviews?r...  2013     8.1   \n",
       "123  https://www.imdb.com/title/tt8579674/reviews?r...  2019     8.2   \n",
       "88   https://www.imdb.com/title/tt0062622/reviews?r...  1968     8.3   \n",
       "86   https://www.imdb.com/title/tt1187043/reviews?r...  2009     8.3   \n",
       "\n",
       "              Movie_ID  \n",
       "4    /title/tt0050083/  \n",
       "182  /title/tt2024544/  \n",
       "123  /title/tt8579674/  \n",
       "88   /title/tt0062622/  \n",
       "86   /title/tt1187043/  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.read_csv(r\"C:\\Users\\joshy\\Desktop\\project\\0_input\\input.csv\")\n",
    "sorted = f.sort_values(by='Title')\n",
    "sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "241c338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Actual Rating'] = f['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6e29baf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies</th>\n",
       "      <th>Scores</th>\n",
       "      <th>No.of.Reviews</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Actual Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>3.785693</td>\n",
       "      <td>25</td>\n",
       "      <td>1.514277</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>3.979807</td>\n",
       "      <td>25</td>\n",
       "      <td>1.591923</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1917</td>\n",
       "      <td>5.576931</td>\n",
       "      <td>25</td>\n",
       "      <td>2.230773</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001 A Space Odyssey</td>\n",
       "      <td>5.568211</td>\n",
       "      <td>25</td>\n",
       "      <td>2.227284</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>2.089509</td>\n",
       "      <td>25</td>\n",
       "      <td>0.835804</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Movies    Scores  No.of.Reviews    Rating  Actual Rating\n",
       "0          12 Angry Men  3.785693             25  1.514277            9.2\n",
       "1      12 Years a Slave  3.979807             25  1.591923            9.2\n",
       "2                  1917  5.576931             25  2.230773            9.0\n",
       "3  2001 A Space Odyssey  5.568211             25  2.227284            9.0\n",
       "4              3 Idiots  2.089509             25  0.835804            8.9"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8719f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'C:/Users/joshy/Desktop/project/output.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "22528f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Seq_num</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Strong_Modal</th>\n",
       "      <th>Weak_Modal</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>1.550080e-08</td>\n",
       "      <td>1.422600e-08</td>\n",
       "      <td>3.815486e-06</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.313627e-10</td>\n",
       "      <td>8.653817e-12</td>\n",
       "      <td>9.241714e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.940882e-10</td>\n",
       "      <td>1.169679e-10</td>\n",
       "      <td>5.290465e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.269840e-09</td>\n",
       "      <td>6.654735e-10</td>\n",
       "      <td>1.595100e-07</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>8570</td>\n",
       "      <td>3.752595e-07</td>\n",
       "      <td>3.809464e-07</td>\n",
       "      <td>3.529356e-05</td>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Seq_num  Word Count  Word Proportion  Average Proportion  \\\n",
       "0   AARDVARK        1         354     1.550080e-08        1.422600e-08   \n",
       "1  AARDVARKS        2           3     1.313627e-10        8.653817e-12   \n",
       "2      ABACI        3           9     3.940882e-10        1.169679e-10   \n",
       "3      ABACK        4          29     1.269840e-09        6.654735e-10   \n",
       "4     ABACUS        5        8570     3.752595e-07        3.809464e-07   \n",
       "\n",
       "        Std Dev  Doc Count  Negative  Positive  Uncertainty  Litigious  \\\n",
       "0  3.815486e-06         99         0         0            0          0   \n",
       "1  9.241714e-09          1         0         0            0          0   \n",
       "2  5.290465e-08          7         0         0            0          0   \n",
       "3  1.595100e-07         28         0         0            0          0   \n",
       "4  3.529356e-05       1108         0         0            0          0   \n",
       "\n",
       "   Strong_Modal  Weak_Modal  Constraining  Syllables     Source  \n",
       "0             0           0             0          2  12of12inf  \n",
       "1             0           0             0          2  12of12inf  \n",
       "2             0           0             0          3  12of12inf  \n",
       "3             0           0             0          2  12of12inf  \n",
       "4             0           0             0          3  12of12inf  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicti = pd.read_csv(r'C:\\Users\\joshy\\Desktop\\project\\Loughran-McDonald_MasterDictionary_1993-2021.csv')\n",
    "dicti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e1b77",
   "metadata": {},
   "source": [
    "### Getting Positive words from the Master Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "40d128ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'acclaimed',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'adequately',\n",
       " 'advancement',\n",
       " 'advancements',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantaged',\n",
       " 'advantageous',\n",
       " 'advantageously',\n",
       " 'advantages',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'assures',\n",
       " 'assuring',\n",
       " 'attain',\n",
       " 'attained',\n",
       " 'attaining',\n",
       " 'attainment',\n",
       " 'attainments',\n",
       " 'attains',\n",
       " 'attractive',\n",
       " 'attractiveness',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beneficially',\n",
       " 'benefited',\n",
       " 'benefiting',\n",
       " 'benefitted',\n",
       " 'benefitting',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bolstered',\n",
       " 'bolstering',\n",
       " 'bolsters',\n",
       " 'boom',\n",
       " 'booming',\n",
       " 'boost',\n",
       " 'boosted',\n",
       " 'breakthrough',\n",
       " 'breakthroughs',\n",
       " 'brilliant',\n",
       " 'charitable',\n",
       " 'collaborate',\n",
       " 'collaborated',\n",
       " 'collaborates',\n",
       " 'collaborating',\n",
       " 'collaboration',\n",
       " 'collaborations',\n",
       " 'collaborative',\n",
       " 'collaborator',\n",
       " 'collaborators',\n",
       " 'compliment',\n",
       " 'complimentary',\n",
       " 'complimented',\n",
       " 'complimenting',\n",
       " 'compliments',\n",
       " 'conclusive',\n",
       " 'conclusively',\n",
       " 'conducive',\n",
       " 'confident',\n",
       " 'constructive',\n",
       " 'constructively',\n",
       " 'courteous',\n",
       " 'creative',\n",
       " 'creatively',\n",
       " 'creativeness',\n",
       " 'creativity',\n",
       " 'delight',\n",
       " 'delighted',\n",
       " 'delightful',\n",
       " 'delightfully',\n",
       " 'delighting',\n",
       " 'delights',\n",
       " 'dependability',\n",
       " 'dependable',\n",
       " 'desirable',\n",
       " 'desired',\n",
       " 'despite',\n",
       " 'destined',\n",
       " 'diligent',\n",
       " 'diligently',\n",
       " 'distinction',\n",
       " 'distinctions',\n",
       " 'distinctive',\n",
       " 'distinctively',\n",
       " 'distinctiveness',\n",
       " 'dream',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'efficiencies',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'efficiently',\n",
       " 'empower',\n",
       " 'empowered',\n",
       " 'empowering',\n",
       " 'empowers',\n",
       " 'enable',\n",
       " 'enabled',\n",
       " 'enables',\n",
       " 'enabling',\n",
       " 'encouraged',\n",
       " 'encouragement',\n",
       " 'encourages',\n",
       " 'encouraging',\n",
       " 'enhance',\n",
       " 'enhanced',\n",
       " 'enhancement',\n",
       " 'enhancements',\n",
       " 'enhances',\n",
       " 'enhancing',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyably',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enjoyment',\n",
       " 'enjoys',\n",
       " 'enthusiasm',\n",
       " 'enthusiastic',\n",
       " 'enthusiastically',\n",
       " 'excellence',\n",
       " 'excellent',\n",
       " 'excelling',\n",
       " 'excels',\n",
       " 'exceptional',\n",
       " 'exceptionally',\n",
       " 'excited',\n",
       " 'excitement',\n",
       " 'exciting',\n",
       " 'exclusive',\n",
       " 'exclusively',\n",
       " 'exclusiveness',\n",
       " 'exclusives',\n",
       " 'exclusivity',\n",
       " 'exemplary',\n",
       " 'fantastic',\n",
       " 'favorable',\n",
       " 'favorably',\n",
       " 'favored',\n",
       " 'favoring',\n",
       " 'favorite',\n",
       " 'favorites',\n",
       " 'friendly',\n",
       " 'gain',\n",
       " 'gained',\n",
       " 'gaining',\n",
       " 'gains',\n",
       " 'good',\n",
       " 'greatest',\n",
       " 'greatly',\n",
       " 'greatness',\n",
       " 'happiest',\n",
       " 'happily',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'highest',\n",
       " 'honor',\n",
       " 'honored',\n",
       " 'honoring',\n",
       " 'honors',\n",
       " 'ideal',\n",
       " 'impress',\n",
       " 'impressed',\n",
       " 'impresses',\n",
       " 'impressing',\n",
       " 'impressive',\n",
       " 'impressively',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'improves',\n",
       " 'improving',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'influential',\n",
       " 'informative',\n",
       " 'ingenuity',\n",
       " 'innovate',\n",
       " 'innovated',\n",
       " 'innovates',\n",
       " 'innovating',\n",
       " 'innovation',\n",
       " 'innovations',\n",
       " 'innovative',\n",
       " 'innovativeness',\n",
       " 'innovator',\n",
       " 'innovators',\n",
       " 'insightful',\n",
       " 'inspiration',\n",
       " 'inspirational',\n",
       " 'integrity',\n",
       " 'invent',\n",
       " 'invented',\n",
       " 'inventing',\n",
       " 'invention',\n",
       " 'inventions',\n",
       " 'inventive',\n",
       " 'inventiveness',\n",
       " 'inventor',\n",
       " 'inventors',\n",
       " 'leadership',\n",
       " 'leading',\n",
       " 'loyal',\n",
       " 'lucrative',\n",
       " 'meritorious',\n",
       " 'opportunities',\n",
       " 'opportunity',\n",
       " 'optimistic',\n",
       " 'outperform',\n",
       " 'outperformed',\n",
       " 'outperforming',\n",
       " 'outperforms',\n",
       " 'perfect',\n",
       " 'perfected',\n",
       " 'perfectly',\n",
       " 'perfects',\n",
       " 'pleasant',\n",
       " 'pleasantly',\n",
       " 'pleased',\n",
       " 'pleasure',\n",
       " 'plentiful',\n",
       " 'popular',\n",
       " 'popularity',\n",
       " 'positive',\n",
       " 'positively',\n",
       " 'preeminence',\n",
       " 'preeminent',\n",
       " 'premier',\n",
       " 'premiere',\n",
       " 'prestige',\n",
       " 'prestigious',\n",
       " 'proactive',\n",
       " 'proactively',\n",
       " 'proficiency',\n",
       " 'proficient',\n",
       " 'proficiently',\n",
       " 'profitability',\n",
       " 'profitable',\n",
       " 'profitably',\n",
       " 'progress',\n",
       " 'progressed',\n",
       " 'progresses',\n",
       " 'progressing',\n",
       " 'prospered',\n",
       " 'prospering',\n",
       " 'prosperity',\n",
       " 'prosperous',\n",
       " 'prospers',\n",
       " 'rebound',\n",
       " 'rebounded',\n",
       " 'rebounding',\n",
       " 'receptive',\n",
       " 'regain',\n",
       " 'regained',\n",
       " 'regaining',\n",
       " 'resolve',\n",
       " 'revolutionize',\n",
       " 'revolutionized',\n",
       " 'revolutionizes',\n",
       " 'revolutionizing',\n",
       " 'reward',\n",
       " 'rewarded',\n",
       " 'rewarding',\n",
       " 'satisfaction',\n",
       " 'satisfactorily',\n",
       " 'satisfactory',\n",
       " 'satisfied',\n",
       " 'satisfies',\n",
       " 'satisfy',\n",
       " 'satisfying',\n",
       " 'smooth',\n",
       " 'smoothing',\n",
       " 'smoothly',\n",
       " 'smooths',\n",
       " 'solves',\n",
       " 'solving',\n",
       " 'spectacular',\n",
       " 'spectacularly',\n",
       " 'stability',\n",
       " 'stabilization',\n",
       " 'stabilizations',\n",
       " 'stabilize',\n",
       " 'stabilized',\n",
       " 'stabilizes',\n",
       " 'stabilizing',\n",
       " 'stable',\n",
       " 'strength',\n",
       " 'strengthen',\n",
       " 'strengthened',\n",
       " 'strengthening',\n",
       " 'strengthens',\n",
       " 'strengths',\n",
       " 'strong',\n",
       " 'stronger',\n",
       " 'strongest',\n",
       " 'succeed',\n",
       " 'succeeded',\n",
       " 'succeeding',\n",
       " 'succeeds',\n",
       " 'success',\n",
       " 'successes',\n",
       " 'successful',\n",
       " 'successfully',\n",
       " 'superior',\n",
       " 'surpass',\n",
       " 'surpassed',\n",
       " 'surpasses',\n",
       " 'surpassing',\n",
       " 'transparency',\n",
       " 'tremendous',\n",
       " 'tremendously',\n",
       " 'unmatched',\n",
       " 'unparalleled',\n",
       " 'unsurpassed',\n",
       " 'upturn',\n",
       " 'upturns',\n",
       " 'valuable',\n",
       " 'versatile',\n",
       " 'versatility',\n",
       " 'vibrancy',\n",
       " 'vibrant',\n",
       " 'win',\n",
       " 'winner',\n",
       " 'winners',\n",
       " 'winning',\n",
       " 'worthy']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = dicti[dicti['Positive'] > 0]\n",
    "pos = [word.lower() for word in pos.Word]\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd16f1",
   "metadata": {},
   "source": [
    "### Getting Negative words from the Master Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bbaa2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandonments',\n",
       " 'abandons',\n",
       " 'abdicated',\n",
       " 'abdicates',\n",
       " 'abdicating',\n",
       " 'abdication',\n",
       " 'abdications',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberrational',\n",
       " 'aberrations',\n",
       " 'abetting',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolishes',\n",
       " 'abolishing',\n",
       " 'abrogate',\n",
       " 'abrogated',\n",
       " 'abrogates',\n",
       " 'abrogating',\n",
       " 'abrogation',\n",
       " 'abrogations',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absenteeism',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abusiveness',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'acquiesce',\n",
       " 'acquiesced',\n",
       " 'acquiesces',\n",
       " 'acquiescing',\n",
       " 'acquit',\n",
       " 'acquits',\n",
       " 'acquittal',\n",
       " 'acquittals',\n",
       " 'acquitted',\n",
       " 'acquitting',\n",
       " 'adulterate',\n",
       " 'adulterated',\n",
       " 'adulterating',\n",
       " 'adulteration',\n",
       " 'adulterations',\n",
       " 'adversarial',\n",
       " 'adversaries',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'adversities',\n",
       " 'adversity',\n",
       " 'aftermath',\n",
       " 'aftermaths',\n",
       " 'against',\n",
       " 'aggravate',\n",
       " 'aggravated',\n",
       " 'aggravates',\n",
       " 'aggravating',\n",
       " 'aggravation',\n",
       " 'aggravations',\n",
       " 'alerted',\n",
       " 'alerting',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienates',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'alienations',\n",
       " 'allegation',\n",
       " 'allegations',\n",
       " 'allege',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'alleges',\n",
       " 'alleging',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyances',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoys',\n",
       " 'annul',\n",
       " 'annulled',\n",
       " 'annulling',\n",
       " 'annulment',\n",
       " 'annulments',\n",
       " 'annuls',\n",
       " 'anomalies',\n",
       " 'anomalous',\n",
       " 'anomalously',\n",
       " 'anomaly',\n",
       " 'anticompetitive',\n",
       " 'antitrust',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'argumentative',\n",
       " 'arguments',\n",
       " 'arrearage',\n",
       " 'arrearages',\n",
       " 'arrears',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrests',\n",
       " 'artificially',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assaulting',\n",
       " 'assaults',\n",
       " 'assertions',\n",
       " 'attrition',\n",
       " 'aversely',\n",
       " 'backdating',\n",
       " 'bad',\n",
       " 'bail',\n",
       " 'bailout',\n",
       " 'balk',\n",
       " 'balked',\n",
       " 'bankrupt',\n",
       " 'bankruptcies',\n",
       " 'bankruptcy',\n",
       " 'bankrupted',\n",
       " 'bankrupting',\n",
       " 'bankrupts',\n",
       " 'bans',\n",
       " 'barred',\n",
       " 'barrier',\n",
       " 'barriers',\n",
       " 'bottleneck',\n",
       " 'bottlenecks',\n",
       " 'boycott',\n",
       " 'boycotted',\n",
       " 'boycotting',\n",
       " 'boycotts',\n",
       " 'breach',\n",
       " 'breached',\n",
       " 'breaches',\n",
       " 'breaching',\n",
       " 'break',\n",
       " 'breakage',\n",
       " 'breakages',\n",
       " 'breakdown',\n",
       " 'breakdowns',\n",
       " 'breaks',\n",
       " 'bribe',\n",
       " 'bribed',\n",
       " 'briberies',\n",
       " 'bribery',\n",
       " 'bribes',\n",
       " 'bribing',\n",
       " 'burden',\n",
       " 'burdened',\n",
       " 'burdening',\n",
       " 'burdens',\n",
       " 'burdensome',\n",
       " 'burned',\n",
       " 'calamities',\n",
       " 'calamitous',\n",
       " 'calamity',\n",
       " 'cancel',\n",
       " 'canceled',\n",
       " 'canceling',\n",
       " 'cancellation',\n",
       " 'cancellations',\n",
       " 'cancelled',\n",
       " 'cancelling',\n",
       " 'cancels',\n",
       " 'careless',\n",
       " 'carelessly',\n",
       " 'carelessness',\n",
       " 'catastrophe',\n",
       " 'catastrophes',\n",
       " 'catastrophic',\n",
       " 'catastrophically',\n",
       " 'caution',\n",
       " 'cautionary',\n",
       " 'cautioned',\n",
       " 'cautioning',\n",
       " 'cautions',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'ceases',\n",
       " 'ceasing',\n",
       " 'censure',\n",
       " 'censured',\n",
       " 'censures',\n",
       " 'censuring',\n",
       " 'challenge',\n",
       " 'challenged',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'chargeoffs',\n",
       " 'circumvent',\n",
       " 'circumvented',\n",
       " 'circumventing',\n",
       " 'circumvention',\n",
       " 'circumventions',\n",
       " 'circumvents',\n",
       " 'claiming',\n",
       " 'claims',\n",
       " 'clawback',\n",
       " 'closeout',\n",
       " 'closeouts',\n",
       " 'closings',\n",
       " 'closure',\n",
       " 'closures',\n",
       " 'coerce',\n",
       " 'coerced',\n",
       " 'coerces',\n",
       " 'coercing',\n",
       " 'coercion',\n",
       " 'coercive',\n",
       " 'collapse',\n",
       " 'collapsed',\n",
       " 'collapses',\n",
       " 'collapsing',\n",
       " 'collision',\n",
       " 'collisions',\n",
       " 'collude',\n",
       " 'colluded',\n",
       " 'colludes',\n",
       " 'colluding',\n",
       " 'collusion',\n",
       " 'collusions',\n",
       " 'collusive',\n",
       " 'complain',\n",
       " 'complained',\n",
       " 'complaining',\n",
       " 'complains',\n",
       " 'complaint',\n",
       " 'complaints',\n",
       " 'complicate',\n",
       " 'complicated',\n",
       " 'complicates',\n",
       " 'complicating',\n",
       " 'complication',\n",
       " 'complications',\n",
       " 'compulsion',\n",
       " 'concealed',\n",
       " 'concealing',\n",
       " 'concede',\n",
       " 'conceded',\n",
       " 'concedes',\n",
       " 'conceding',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerns',\n",
       " 'conciliating',\n",
       " 'conciliation',\n",
       " 'conciliations',\n",
       " 'condemn',\n",
       " 'condemnation',\n",
       " 'condemnations',\n",
       " 'condemned',\n",
       " 'condemning',\n",
       " 'condemns',\n",
       " 'condone',\n",
       " 'condoned',\n",
       " 'confess',\n",
       " 'confessed',\n",
       " 'confesses',\n",
       " 'confessing',\n",
       " 'confession',\n",
       " 'confine',\n",
       " 'confined',\n",
       " 'confinement',\n",
       " 'confinements',\n",
       " 'confines',\n",
       " 'confining',\n",
       " 'confiscate',\n",
       " 'confiscated',\n",
       " 'confiscates',\n",
       " 'confiscating',\n",
       " 'confiscation',\n",
       " 'confiscations',\n",
       " 'conflict',\n",
       " 'conflicted',\n",
       " 'conflicting',\n",
       " 'conflicts',\n",
       " 'confront',\n",
       " 'confrontation',\n",
       " 'confrontational',\n",
       " 'confrontations',\n",
       " 'confronted',\n",
       " 'confronting',\n",
       " 'confronts',\n",
       " 'confuse',\n",
       " 'confused',\n",
       " 'confuses',\n",
       " 'confusing',\n",
       " 'confusingly',\n",
       " 'confusion',\n",
       " 'conspiracies',\n",
       " 'conspiracy',\n",
       " 'conspirator',\n",
       " 'conspiratorial',\n",
       " 'conspirators',\n",
       " 'conspire',\n",
       " 'conspired',\n",
       " 'conspires',\n",
       " 'conspiring',\n",
       " 'contempt',\n",
       " 'contend',\n",
       " 'contended',\n",
       " 'contending',\n",
       " 'contends',\n",
       " 'contention',\n",
       " 'contentions',\n",
       " 'contentious',\n",
       " 'contentiously',\n",
       " 'contested',\n",
       " 'contesting',\n",
       " 'contraction',\n",
       " 'contractions',\n",
       " 'contradict',\n",
       " 'contradicted',\n",
       " 'contradicting',\n",
       " 'contradiction',\n",
       " 'contradictions',\n",
       " 'contradictory',\n",
       " 'contradicts',\n",
       " 'contrary',\n",
       " 'controversial',\n",
       " 'controversies',\n",
       " 'controversy',\n",
       " 'convict',\n",
       " 'convicted',\n",
       " 'convicting',\n",
       " 'conviction',\n",
       " 'convictions',\n",
       " 'corrected',\n",
       " 'correcting',\n",
       " 'correction',\n",
       " 'corrections',\n",
       " 'corrects',\n",
       " 'corrupt',\n",
       " 'corrupted',\n",
       " 'corrupting',\n",
       " 'corruption',\n",
       " 'corruptions',\n",
       " 'corruptly',\n",
       " 'corruptness',\n",
       " 'costly',\n",
       " 'counterclaim',\n",
       " 'counterclaimed',\n",
       " 'counterclaiming',\n",
       " 'counterclaims',\n",
       " 'counterfeit',\n",
       " 'counterfeited',\n",
       " 'counterfeiter',\n",
       " 'counterfeiters',\n",
       " 'counterfeiting',\n",
       " 'counterfeits',\n",
       " 'countermeasure',\n",
       " 'countermeasures',\n",
       " 'crime',\n",
       " 'crimes',\n",
       " 'criminal',\n",
       " 'criminally',\n",
       " 'criminals',\n",
       " 'crises',\n",
       " 'crisis',\n",
       " 'critically',\n",
       " 'criticism',\n",
       " 'criticisms',\n",
       " 'criticize',\n",
       " 'criticized',\n",
       " 'criticizes',\n",
       " 'criticizing',\n",
       " 'crucial',\n",
       " 'crucially',\n",
       " 'culpability',\n",
       " 'culpable',\n",
       " 'culpably',\n",
       " 'cumbersome',\n",
       " 'curtail',\n",
       " 'curtailed',\n",
       " 'curtailing',\n",
       " 'curtailment',\n",
       " 'curtailments',\n",
       " 'curtails',\n",
       " 'cut',\n",
       " 'cutback',\n",
       " 'cutbacks',\n",
       " 'cyberattack',\n",
       " 'cyberattacks',\n",
       " 'cyberbullying',\n",
       " 'cybercrime',\n",
       " 'cybercrimes',\n",
       " 'cybercriminal',\n",
       " 'cybercriminals',\n",
       " 'damage',\n",
       " 'damaged',\n",
       " 'damages',\n",
       " 'damaging',\n",
       " 'dampen',\n",
       " 'dampened',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'dangerously',\n",
       " 'dangers',\n",
       " 'deadlock',\n",
       " 'deadlocked',\n",
       " 'deadlocking',\n",
       " 'deadlocks',\n",
       " 'deadweight',\n",
       " 'deadweights',\n",
       " 'debarment',\n",
       " 'debarments',\n",
       " 'debarred',\n",
       " 'deceased',\n",
       " 'deceit',\n",
       " 'deceitful',\n",
       " 'deceitfulness',\n",
       " 'deceive',\n",
       " 'deceived',\n",
       " 'deceives',\n",
       " 'deceiving',\n",
       " 'deception',\n",
       " 'deceptions',\n",
       " 'deceptive',\n",
       " 'deceptively',\n",
       " 'decline',\n",
       " 'declined',\n",
       " 'declines',\n",
       " 'declining',\n",
       " 'deface',\n",
       " 'defaced',\n",
       " 'defacement',\n",
       " 'defamation',\n",
       " 'defamations',\n",
       " 'defamatory',\n",
       " 'defame',\n",
       " 'defamed',\n",
       " 'defames',\n",
       " 'defaming',\n",
       " 'default',\n",
       " 'defaulted',\n",
       " 'defaulting',\n",
       " 'defaults',\n",
       " 'defeat',\n",
       " 'defeated',\n",
       " 'defeating',\n",
       " 'defeats',\n",
       " 'defect',\n",
       " 'defective',\n",
       " 'defects',\n",
       " 'defend',\n",
       " 'defendant',\n",
       " 'defendants',\n",
       " 'defended',\n",
       " 'defending',\n",
       " 'defends',\n",
       " 'defensive',\n",
       " 'defer',\n",
       " 'deficiencies',\n",
       " 'deficiency',\n",
       " 'deficient',\n",
       " 'deficit',\n",
       " 'deficits',\n",
       " 'defraud',\n",
       " 'defrauded',\n",
       " 'defrauding',\n",
       " 'defrauds',\n",
       " 'defunct',\n",
       " 'degradation',\n",
       " 'degradations',\n",
       " 'degrade',\n",
       " 'degraded',\n",
       " 'degrades',\n",
       " 'degrading',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delaying',\n",
       " 'delays',\n",
       " 'deleterious',\n",
       " 'deliberate',\n",
       " 'deliberated',\n",
       " 'deliberately',\n",
       " 'delinquencies',\n",
       " 'delinquency',\n",
       " 'delinquent',\n",
       " 'delinquently',\n",
       " 'delinquents',\n",
       " 'delist',\n",
       " 'delisted',\n",
       " 'delisting',\n",
       " 'delists',\n",
       " 'demise',\n",
       " 'demised',\n",
       " 'demises',\n",
       " 'demising',\n",
       " 'demolish',\n",
       " 'demolished',\n",
       " 'demolishes',\n",
       " 'demolishing',\n",
       " 'demolition',\n",
       " 'demolitions',\n",
       " 'demote',\n",
       " 'demoted',\n",
       " 'demotes',\n",
       " 'demoting',\n",
       " 'demotion',\n",
       " 'demotions',\n",
       " 'denial',\n",
       " 'denials',\n",
       " 'denied',\n",
       " 'denies',\n",
       " 'denigrate',\n",
       " 'denigrated',\n",
       " 'denigrates',\n",
       " 'denigrating',\n",
       " 'denigration',\n",
       " 'deny',\n",
       " 'denying',\n",
       " 'deplete',\n",
       " 'depleted',\n",
       " 'depletes',\n",
       " 'depleting',\n",
       " 'depletion',\n",
       " 'depletions',\n",
       " 'deprecation',\n",
       " 'depress',\n",
       " 'depressed',\n",
       " 'depresses',\n",
       " 'depressing',\n",
       " 'deprivation',\n",
       " 'deprive',\n",
       " 'deprived',\n",
       " 'deprives',\n",
       " 'depriving',\n",
       " 'derelict',\n",
       " 'dereliction',\n",
       " 'derogatory',\n",
       " 'destabilization',\n",
       " 'destabilize',\n",
       " 'destabilized',\n",
       " 'destabilizing',\n",
       " 'destroy',\n",
       " 'destroyed',\n",
       " 'destroying',\n",
       " 'destroys',\n",
       " 'destruction',\n",
       " 'destructive',\n",
       " 'detain',\n",
       " 'detained',\n",
       " 'detention',\n",
       " 'detentions',\n",
       " 'deter',\n",
       " 'deteriorate',\n",
       " 'deteriorated',\n",
       " 'deteriorates',\n",
       " 'deteriorating',\n",
       " 'deterioration',\n",
       " 'deteriorations',\n",
       " 'deterred',\n",
       " 'deterrence',\n",
       " 'deterrences',\n",
       " 'deterrent',\n",
       " 'deterrents',\n",
       " 'deterring',\n",
       " 'deters',\n",
       " 'detract',\n",
       " 'detracted',\n",
       " 'detracting',\n",
       " 'detriment',\n",
       " 'detrimental',\n",
       " 'detrimentally',\n",
       " 'detriments',\n",
       " 'devalue',\n",
       " 'devalued',\n",
       " 'devalues',\n",
       " 'devaluing',\n",
       " 'devastate',\n",
       " 'devastated',\n",
       " 'devastating',\n",
       " 'devastation',\n",
       " 'deviate',\n",
       " 'deviated',\n",
       " 'deviates',\n",
       " 'deviating',\n",
       " 'deviation',\n",
       " 'deviations',\n",
       " 'devolve',\n",
       " 'devolved',\n",
       " 'devolves',\n",
       " 'devolving',\n",
       " 'difficult',\n",
       " 'difficulties',\n",
       " 'difficultly',\n",
       " 'difficulty',\n",
       " 'diminish',\n",
       " 'diminished',\n",
       " 'diminishes',\n",
       " 'diminishing',\n",
       " 'diminution',\n",
       " 'disadvantage',\n",
       " 'disadvantaged',\n",
       " 'disadvantageous',\n",
       " 'disadvantages',\n",
       " 'disaffiliation',\n",
       " 'disagree',\n",
       " 'disagreeable',\n",
       " 'disagreed',\n",
       " 'disagreeing',\n",
       " 'disagreement',\n",
       " 'disagreements',\n",
       " 'disagrees',\n",
       " 'disallow',\n",
       " 'disallowance',\n",
       " 'disallowances',\n",
       " 'disallowed',\n",
       " 'disallowing',\n",
       " 'disallows',\n",
       " 'disappear',\n",
       " 'disappearance',\n",
       " 'disappearances',\n",
       " 'disappeared',\n",
       " 'disappearing',\n",
       " 'disappears',\n",
       " 'disappoint',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disappointingly',\n",
       " 'disappointment',\n",
       " 'disappointments',\n",
       " 'disappoints',\n",
       " 'disapproval',\n",
       " 'disapprovals',\n",
       " 'disapprove',\n",
       " 'disapproved',\n",
       " 'disapproves',\n",
       " 'disapproving',\n",
       " 'disassociates',\n",
       " 'disassociating',\n",
       " 'disassociation',\n",
       " 'disassociations',\n",
       " 'disaster',\n",
       " 'disasters',\n",
       " 'disastrous',\n",
       " 'disastrously',\n",
       " 'disavow',\n",
       " 'disavowal',\n",
       " 'disavowed',\n",
       " 'disavowing',\n",
       " 'disavows',\n",
       " 'disciplinary',\n",
       " 'disclaim',\n",
       " 'disclaimed',\n",
       " 'disclaimer',\n",
       " 'disclaimers',\n",
       " 'disclaiming',\n",
       " 'disclaims',\n",
       " 'disclose',\n",
       " 'disclosed',\n",
       " 'discloses',\n",
       " 'disclosing',\n",
       " 'discontinuance',\n",
       " 'discontinuances',\n",
       " 'discontinuation',\n",
       " 'discontinuations',\n",
       " 'discontinue',\n",
       " 'discontinued',\n",
       " 'discontinues',\n",
       " 'discontinuing',\n",
       " 'discourage',\n",
       " 'discouraged',\n",
       " 'discourages',\n",
       " 'discouraging',\n",
       " 'discredit',\n",
       " 'discredited',\n",
       " 'discrediting',\n",
       " 'discredits',\n",
       " 'discrepancies',\n",
       " 'discrepancy',\n",
       " 'disfavor',\n",
       " 'disfavored',\n",
       " 'disfavoring',\n",
       " 'disfavors',\n",
       " 'disgorge',\n",
       " 'disgorged',\n",
       " 'disgorgement',\n",
       " 'disgorgements',\n",
       " 'disgorges',\n",
       " 'disgorging',\n",
       " 'disgrace',\n",
       " 'disgraceful',\n",
       " 'disgracefully',\n",
       " 'dishonest',\n",
       " 'dishonestly',\n",
       " 'dishonesty',\n",
       " 'dishonor',\n",
       " 'dishonorable',\n",
       " 'dishonorably',\n",
       " 'dishonored',\n",
       " 'dishonoring',\n",
       " 'dishonors',\n",
       " 'disincentives',\n",
       " 'disinterested',\n",
       " 'disinterestedly',\n",
       " 'disinterestedness',\n",
       " 'disloyal',\n",
       " 'disloyally',\n",
       " 'disloyalty',\n",
       " 'dismal',\n",
       " 'dismally',\n",
       " 'dismiss',\n",
       " 'dismissal',\n",
       " 'dismissals',\n",
       " 'dismissed',\n",
       " 'dismisses',\n",
       " 'dismissing',\n",
       " 'disorderly',\n",
       " 'disparage',\n",
       " 'disparaged',\n",
       " 'disparagement',\n",
       " 'disparagements',\n",
       " 'disparages',\n",
       " 'disparaging',\n",
       " 'disparagingly',\n",
       " 'disparities',\n",
       " 'disparity',\n",
       " 'displace',\n",
       " 'displaced',\n",
       " 'displacement',\n",
       " 'displacements',\n",
       " 'displaces',\n",
       " 'displacing',\n",
       " 'dispose',\n",
       " 'dispossess',\n",
       " 'dispossessed',\n",
       " 'dispossesses',\n",
       " 'dispossessing',\n",
       " 'disproportion',\n",
       " 'disproportional',\n",
       " 'disproportionate',\n",
       " 'disproportionately',\n",
       " 'dispute',\n",
       " 'disputed',\n",
       " 'disputes',\n",
       " 'disputing',\n",
       " 'disqualification',\n",
       " 'disqualifications',\n",
       " 'disqualified',\n",
       " 'disqualifies',\n",
       " 'disqualify',\n",
       " 'disqualifying',\n",
       " 'disregard',\n",
       " 'disregarded',\n",
       " 'disregarding',\n",
       " 'disregards',\n",
       " 'disreputable',\n",
       " 'disrepute',\n",
       " 'disrupt',\n",
       " 'disrupted',\n",
       " 'disrupting',\n",
       " 'disruption',\n",
       " 'disruptions',\n",
       " 'disruptive',\n",
       " 'disrupts',\n",
       " 'dissatisfaction',\n",
       " 'dissatisfied',\n",
       " 'dissent',\n",
       " 'dissented',\n",
       " 'dissenter',\n",
       " 'dissenters',\n",
       " 'dissenting',\n",
       " 'dissents',\n",
       " 'dissident',\n",
       " 'dissidents',\n",
       " 'dissolution',\n",
       " 'dissolutions',\n",
       " 'distort',\n",
       " 'distorted',\n",
       " 'distorting',\n",
       " 'distortion',\n",
       " 'distortions',\n",
       " 'distorts',\n",
       " 'distract',\n",
       " 'distracted',\n",
       " 'distracting',\n",
       " 'distraction',\n",
       " 'distractions',\n",
       " 'distracts',\n",
       " 'distress',\n",
       " 'distressed',\n",
       " 'disturb',\n",
       " 'disturbance',\n",
       " 'disturbances',\n",
       " 'disturbed',\n",
       " 'disturbing',\n",
       " 'disturbs',\n",
       " 'diversion',\n",
       " 'divert',\n",
       " 'diverted',\n",
       " 'diverting',\n",
       " 'diverts',\n",
       " 'divest',\n",
       " 'divested',\n",
       " 'divesting',\n",
       " 'divestiture',\n",
       " 'divestitures',\n",
       " 'divestment',\n",
       " 'divestments',\n",
       " 'divests',\n",
       " 'divorce',\n",
       " 'divorced',\n",
       " 'divulge',\n",
       " 'divulged',\n",
       " 'divulges',\n",
       " 'divulging',\n",
       " 'doubt',\n",
       " 'doubted',\n",
       " 'doubtful',\n",
       " 'doubts',\n",
       " 'downgrade',\n",
       " 'downgraded',\n",
       " 'downgrades',\n",
       " 'downgrading',\n",
       " 'downsize',\n",
       " 'downsized',\n",
       " 'downsizes',\n",
       " 'downsizing',\n",
       " 'downsizings',\n",
       " 'downtime',\n",
       " 'downtimes',\n",
       " 'downturn',\n",
       " 'downturns',\n",
       " 'downward',\n",
       " 'downwards',\n",
       " 'drag',\n",
       " 'drastic',\n",
       " 'drastically',\n",
       " 'drawback',\n",
       " 'drawbacks',\n",
       " 'dropped',\n",
       " 'drought',\n",
       " 'droughts',\n",
       " 'duress',\n",
       " 'dysfunction',\n",
       " 'dysfunctional',\n",
       " 'dysfunctions',\n",
       " 'easing',\n",
       " 'egregious',\n",
       " 'egregiously',\n",
       " 'embargo',\n",
       " 'embargoed',\n",
       " 'embargoes',\n",
       " 'embargoing',\n",
       " 'embarrass',\n",
       " 'embarrassed',\n",
       " 'embarrasses',\n",
       " 'embarrassing',\n",
       " 'embarrassment',\n",
       " 'embarrassments',\n",
       " 'embezzle',\n",
       " 'embezzled',\n",
       " 'embezzlement',\n",
       " 'embezzlements',\n",
       " 'embezzler',\n",
       " 'embezzles',\n",
       " 'embezzling',\n",
       " 'encroach',\n",
       " 'encroached',\n",
       " 'encroaches',\n",
       " 'encroaching',\n",
       " 'encroachment',\n",
       " 'encroachments',\n",
       " 'encumber',\n",
       " 'encumbered',\n",
       " 'encumbering',\n",
       " 'encumbers',\n",
       " 'encumbrance',\n",
       " 'encumbrances',\n",
       " 'endanger',\n",
       " 'endangered',\n",
       " 'endangering',\n",
       " 'endangerment',\n",
       " 'endangers',\n",
       " 'enjoin',\n",
       " 'enjoined',\n",
       " 'enjoining',\n",
       " 'enjoins',\n",
       " 'erode',\n",
       " 'eroded',\n",
       " 'erodes',\n",
       " 'eroding',\n",
       " 'erosion',\n",
       " 'erratic',\n",
       " 'erratically',\n",
       " 'erred',\n",
       " 'erring',\n",
       " 'erroneous',\n",
       " 'erroneously',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'errs',\n",
       " 'escalate',\n",
       " 'escalated',\n",
       " 'escalates',\n",
       " 'escalating',\n",
       " 'evade',\n",
       " 'evaded',\n",
       " 'evades',\n",
       " 'evading',\n",
       " 'evasion',\n",
       " 'evasions',\n",
       " 'evasive',\n",
       " 'evict',\n",
       " 'evicted',\n",
       " 'evicting',\n",
       " 'eviction',\n",
       " 'evictions',\n",
       " 'evicts',\n",
       " 'exacerbate',\n",
       " 'exacerbated',\n",
       " 'exacerbates',\n",
       " 'exacerbating',\n",
       " 'exacerbation',\n",
       " 'exacerbations',\n",
       " 'exaggerate',\n",
       " 'exaggerated',\n",
       " 'exaggerates',\n",
       " 'exaggerating',\n",
       " 'exaggeration',\n",
       " 'excessive',\n",
       " 'excessively',\n",
       " 'exculpate',\n",
       " 'exculpated',\n",
       " 'exculpates',\n",
       " 'exculpating',\n",
       " 'exculpation',\n",
       " 'exculpations',\n",
       " 'exculpatory',\n",
       " 'exonerate',\n",
       " 'exonerated',\n",
       " 'exonerates',\n",
       " 'exonerating',\n",
       " 'exoneration',\n",
       " 'exonerations',\n",
       " 'exploit',\n",
       " 'exploitation',\n",
       " 'exploitations',\n",
       " 'exploitative',\n",
       " 'exploited',\n",
       " 'exploiting',\n",
       " 'exploits',\n",
       " 'expose',\n",
       " 'exposed',\n",
       " 'exposes',\n",
       " 'exposing',\n",
       " 'expropriate',\n",
       " 'expropriated',\n",
       " 'expropriates',\n",
       " 'expropriating',\n",
       " 'expropriation',\n",
       " 'expropriations',\n",
       " 'expulsion',\n",
       " 'expulsions',\n",
       " 'extenuating',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'failings',\n",
       " 'fails',\n",
       " 'failure',\n",
       " 'failures',\n",
       " 'fallout',\n",
       " 'false',\n",
       " 'falsely',\n",
       " 'falsification',\n",
       " 'falsifications',\n",
       " 'falsified',\n",
       " 'falsifies',\n",
       " 'falsify',\n",
       " ...]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = dicti[dicti['Negative'] > 0]\n",
    "neg = [word.lower() for word in neg.Word]\n",
    "neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410249de",
   "metadata": {},
   "source": [
    "### Getting Complex words from the Master Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "35c33189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaci',\n",
       " 'abacus',\n",
       " 'abacuses',\n",
       " 'abalone',\n",
       " 'abalones',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandonments',\n",
       " 'abandons',\n",
       " 'abasement',\n",
       " 'abasements',\n",
       " 'abases',\n",
       " 'abashedly',\n",
       " 'abashes',\n",
       " 'abashing',\n",
       " 'abashment',\n",
       " 'abashments',\n",
       " 'abasing',\n",
       " 'abated',\n",
       " 'abatement',\n",
       " 'abatements',\n",
       " 'abating',\n",
       " 'abattoir',\n",
       " 'abattoirs',\n",
       " 'abbesses',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abbreviates',\n",
       " 'abbreviating',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abdicate',\n",
       " 'abdicated',\n",
       " 'abdicates',\n",
       " 'abdicating',\n",
       " 'abdication',\n",
       " 'abdications',\n",
       " 'abdomen',\n",
       " 'abdomens',\n",
       " 'abdominal',\n",
       " 'abdominals',\n",
       " 'abducted',\n",
       " 'abducting',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abductor',\n",
       " 'abductors',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberrational',\n",
       " 'aberrations',\n",
       " 'abetted',\n",
       " 'abetter',\n",
       " 'abetters',\n",
       " 'abetting',\n",
       " 'abettor',\n",
       " 'abettors',\n",
       " 'abeyance',\n",
       " 'abeyances',\n",
       " 'abhorrence',\n",
       " 'abhorrences',\n",
       " 'abhorrent',\n",
       " 'abhorrently',\n",
       " 'abhorring',\n",
       " 'abidance',\n",
       " 'abidances',\n",
       " 'abided',\n",
       " 'abiding',\n",
       " 'abidingly',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abjection',\n",
       " 'abjections',\n",
       " 'abjectly',\n",
       " 'abjectness',\n",
       " 'abjectnesses',\n",
       " 'abjuration',\n",
       " 'abjurations',\n",
       " 'abjuratory',\n",
       " 'abjurer',\n",
       " 'abjurers',\n",
       " 'abjuring',\n",
       " 'ablated',\n",
       " 'ablating',\n",
       " 'ablation',\n",
       " 'ablations',\n",
       " 'ablative',\n",
       " 'ablatives',\n",
       " 'ablution',\n",
       " 'ablutions',\n",
       " 'abnegate',\n",
       " 'abnegated',\n",
       " 'abnegates',\n",
       " 'abnegating',\n",
       " 'abnegation',\n",
       " 'abnegations',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolishes',\n",
       " 'abolishing',\n",
       " 'abolition',\n",
       " 'abolitionism',\n",
       " 'abolitionisms',\n",
       " 'abolitionist',\n",
       " 'abolitionists',\n",
       " 'abolitions',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abominated',\n",
       " 'abominates',\n",
       " 'abominating',\n",
       " 'abomination',\n",
       " 'abominations',\n",
       " 'aboriginal',\n",
       " 'aboriginals',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'aborning',\n",
       " 'aborted',\n",
       " 'aborting',\n",
       " 'abortion',\n",
       " 'abortionist',\n",
       " 'abortionists',\n",
       " 'abortions',\n",
       " 'abortive',\n",
       " 'abortively',\n",
       " 'abounded',\n",
       " 'abounding',\n",
       " 'aboveboard',\n",
       " 'aboveground',\n",
       " 'abovementioned',\n",
       " 'abracadabra',\n",
       " 'abracadabras',\n",
       " 'abraded',\n",
       " 'abrading',\n",
       " 'abrasion',\n",
       " 'abrasions',\n",
       " 'abrasive',\n",
       " 'abrasively',\n",
       " 'abrasiveness',\n",
       " 'abrasivenesses',\n",
       " 'abrasives',\n",
       " 'abridgement',\n",
       " 'abridgements',\n",
       " 'abridges',\n",
       " 'abridging',\n",
       " 'abridgment',\n",
       " 'abridgments',\n",
       " 'abrogate',\n",
       " 'abrogated',\n",
       " 'abrogates',\n",
       " 'abrogating',\n",
       " 'abrogation',\n",
       " 'abrogations',\n",
       " 'abrogator',\n",
       " 'abrogators',\n",
       " 'abrupter',\n",
       " 'abruptest',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'abruptnesses',\n",
       " 'abscesses',\n",
       " 'abscessing',\n",
       " 'abscissa',\n",
       " 'abscissae',\n",
       " 'abscissas',\n",
       " 'abscission',\n",
       " 'abscissions',\n",
       " 'absconded',\n",
       " 'absconder',\n",
       " 'absconders',\n",
       " 'absconding',\n",
       " 'abseiling',\n",
       " 'absences',\n",
       " 'absented',\n",
       " 'absentee',\n",
       " 'absenteeism',\n",
       " 'absenteeisms',\n",
       " 'absentees',\n",
       " 'absenting',\n",
       " 'absently',\n",
       " 'absentminded',\n",
       " 'absentmindedly',\n",
       " 'absentmindedness',\n",
       " 'absentmindednesses',\n",
       " 'absinthes',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absoluteness',\n",
       " 'absolutenesses',\n",
       " 'absolutes',\n",
       " 'absolutest',\n",
       " 'absolution',\n",
       " 'absolutions',\n",
       " 'absolutism',\n",
       " 'absolutisms',\n",
       " 'absolutist',\n",
       " 'absolutists',\n",
       " 'absolving',\n",
       " 'absorbable',\n",
       " 'absorbencies',\n",
       " 'absorbency',\n",
       " 'absorbent',\n",
       " 'absorbents',\n",
       " 'absorber',\n",
       " 'absorbers',\n",
       " 'absorbing',\n",
       " 'absorbingly',\n",
       " 'absorption',\n",
       " 'absorptions',\n",
       " 'absorptive',\n",
       " 'abstainer',\n",
       " 'abstainers',\n",
       " 'abstaining',\n",
       " 'abstemious',\n",
       " 'abstemiously',\n",
       " 'abstemiousness',\n",
       " 'abstemiousnesses',\n",
       " 'abstention',\n",
       " 'abstentions',\n",
       " 'abstinence',\n",
       " 'abstinences',\n",
       " 'abstinent',\n",
       " 'abstracted',\n",
       " 'abstractedly',\n",
       " 'abstractedness',\n",
       " 'abstractednesses',\n",
       " 'abstracting',\n",
       " 'abstraction',\n",
       " 'abstractions',\n",
       " 'abstractly',\n",
       " 'abstractness',\n",
       " 'abstractnesses',\n",
       " 'abstrusely',\n",
       " 'abstruseness',\n",
       " 'abstrusenesses',\n",
       " 'absurder',\n",
       " 'absurdest',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'absurdness',\n",
       " 'absurdnesses',\n",
       " 'abundance',\n",
       " 'abundances',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abusiveness',\n",
       " 'abusivenesses',\n",
       " 'abutment',\n",
       " 'abutments',\n",
       " 'abutted',\n",
       " 'abutting',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyssal',\n",
       " 'abysses',\n",
       " 'acacia',\n",
       " 'acacias',\n",
       " 'academe',\n",
       " 'academes',\n",
       " 'academia',\n",
       " 'academias',\n",
       " 'academic',\n",
       " 'academically',\n",
       " 'academician',\n",
       " 'academicians',\n",
       " 'academics',\n",
       " 'academies',\n",
       " 'academy',\n",
       " 'acanthi',\n",
       " 'acanthus',\n",
       " 'acanthuses',\n",
       " 'acceded',\n",
       " 'acceding',\n",
       " 'accelerant',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerates',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'accelerometer',\n",
       " 'accented',\n",
       " 'accenting',\n",
       " 'accentual',\n",
       " 'accentuate',\n",
       " 'accentuated',\n",
       " 'accentuates',\n",
       " 'accentuating',\n",
       " 'accentuation',\n",
       " 'accentuations',\n",
       " 'acceptabilities',\n",
       " 'acceptability',\n",
       " 'acceptable',\n",
       " 'acceptableness',\n",
       " 'acceptablenesses',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'acceptances',\n",
       " 'acceptation',\n",
       " 'acceptations',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'acceptor',\n",
       " 'accesses',\n",
       " 'accessibilities',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessibly',\n",
       " 'accessing',\n",
       " 'accession',\n",
       " 'accessions',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'accessways',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidentals',\n",
       " 'accidents',\n",
       " 'acclaiming',\n",
       " 'acclamation',\n",
       " 'acclamations',\n",
       " 'acclimate',\n",
       " 'acclimated',\n",
       " 'acclimates',\n",
       " 'acclimating',\n",
       " 'acclimation',\n",
       " 'acclimations',\n",
       " 'acclimatization',\n",
       " 'acclimatizations',\n",
       " 'acclimatize',\n",
       " 'acclimatized',\n",
       " 'acclimatizes',\n",
       " 'acclimatizing',\n",
       " 'acclivities',\n",
       " 'acclivity',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accommodatingly',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accommodative',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompaniments',\n",
       " 'accompanist',\n",
       " 'accompanists',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accordance',\n",
       " 'accordances',\n",
       " 'accordant',\n",
       " 'accorded',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accordionist',\n",
       " 'accordionists',\n",
       " 'accordions',\n",
       " 'accosted',\n",
       " 'accosting',\n",
       " 'accountabilities',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountancies',\n",
       " 'accountancy',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accounted',\n",
       " 'accountholder',\n",
       " 'accountholders',\n",
       " 'accounting',\n",
       " 'accountings',\n",
       " 'accouter',\n",
       " 'accoutered',\n",
       " 'accoutering',\n",
       " 'accouterments',\n",
       " 'accouters',\n",
       " 'accoutre',\n",
       " 'accoutred',\n",
       " 'accoutrements',\n",
       " 'accoutres',\n",
       " 'accoutring',\n",
       " 'accredit',\n",
       " 'accreditation',\n",
       " 'accreditations',\n",
       " 'accredited',\n",
       " 'accrediting',\n",
       " 'accredits',\n",
       " 'accretable',\n",
       " 'accreted',\n",
       " 'accreting',\n",
       " 'accretion',\n",
       " 'accretionary',\n",
       " 'accretions',\n",
       " 'accretive',\n",
       " 'accretively',\n",
       " 'accretiveness',\n",
       " 'accruable',\n",
       " 'accrual',\n",
       " 'accruals',\n",
       " 'accruing',\n",
       " 'acculturate',\n",
       " 'acculturated',\n",
       " 'acculturates',\n",
       " 'acculturating',\n",
       " 'acculturation',\n",
       " 'acculturations',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accumulating',\n",
       " 'accumulation',\n",
       " 'accumulations',\n",
       " 'accumulative',\n",
       " 'accumulator',\n",
       " 'accumulators',\n",
       " 'accuracies',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accurateness',\n",
       " 'accuratenesses',\n",
       " 'accursed',\n",
       " 'accursedness',\n",
       " 'accursednesses',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accusative',\n",
       " 'accusatives',\n",
       " 'accusatory',\n",
       " 'accuser',\n",
       " 'accusers',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accusingly',\n",
       " 'accustom',\n",
       " 'accustomed',\n",
       " 'accustoming',\n",
       " 'accustoms',\n",
       " 'acerbate',\n",
       " 'acerbated',\n",
       " 'acerbates',\n",
       " 'acerbating',\n",
       " 'acerbic',\n",
       " 'acerbically',\n",
       " 'acerbities',\n",
       " 'acerbity',\n",
       " 'acetaminophen',\n",
       " 'acetaminophens',\n",
       " 'acetate',\n",
       " 'acetates',\n",
       " 'acetic',\n",
       " 'acetone',\n",
       " 'acetones',\n",
       " 'acetonic',\n",
       " 'acetylene',\n",
       " 'acetylenes',\n",
       " 'achier',\n",
       " 'achiest',\n",
       " 'achievability',\n",
       " 'achievable',\n",
       " 'achieveable',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achiever',\n",
       " 'achievers',\n",
       " 'achieving',\n",
       " 'achromatic',\n",
       " 'acidic',\n",
       " 'acidified',\n",
       " 'acidifies',\n",
       " 'acidify',\n",
       " 'acidifying',\n",
       " 'acidities',\n",
       " 'acidity',\n",
       " 'acidly',\n",
       " 'acidoses',\n",
       " 'acidosis',\n",
       " 'acidulous',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledgements',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acknowledgments',\n",
       " 'acolyte',\n",
       " 'acolytes',\n",
       " 'aconite',\n",
       " 'aconites',\n",
       " 'acoustic',\n",
       " 'acoustical',\n",
       " 'acoustically',\n",
       " 'acoustics',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquaintanceship',\n",
       " 'acquaintanceships',\n",
       " 'acquainted',\n",
       " 'acquainting',\n",
       " 'acquiesce',\n",
       " 'acquiesced',\n",
       " 'acquiescence',\n",
       " 'acquiescences',\n",
       " 'acquiescent',\n",
       " 'acquiescently',\n",
       " 'acquiesces',\n",
       " 'acquiescing',\n",
       " 'acquirable',\n",
       " 'acquiree',\n",
       " 'acquirees',\n",
       " 'acquirement',\n",
       " 'acquirements',\n",
       " 'acquirer',\n",
       " 'acquirers',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquiror',\n",
       " 'acquirors',\n",
       " 'acquisition',\n",
       " 'acquisitional',\n",
       " 'acquisitions',\n",
       " 'acquisitive',\n",
       " 'acquisitively',\n",
       " 'acquisitiveness',\n",
       " 'acquisitivenesses',\n",
       " 'acquittal',\n",
       " 'acquittals',\n",
       " 'acquittance',\n",
       " 'acquittances',\n",
       " 'acquitted',\n",
       " 'acquitting',\n",
       " 'acreage',\n",
       " 'acreages',\n",
       " 'acrider',\n",
       " 'acridest',\n",
       " 'acridities',\n",
       " 'acridity',\n",
       " 'acridly',\n",
       " 'acridness',\n",
       " 'acridnesses',\n",
       " 'acrimonies',\n",
       " 'acrimonious',\n",
       " 'acrimoniously',\n",
       " 'acrimoniousness',\n",
       " 'acrimoniousnesses',\n",
       " 'acrimony',\n",
       " 'acrobat',\n",
       " 'acrobatic',\n",
       " 'acrobatically',\n",
       " 'acrobatics',\n",
       " 'acrobats',\n",
       " 'acronym',\n",
       " 'acronyms',\n",
       " 'acrophobia',\n",
       " 'acrophobias',\n",
       " 'acropolis',\n",
       " 'acropolises',\n",
       " 'acrostic',\n",
       " 'acrostics',\n",
       " 'acrylic',\n",
       " 'acrylics',\n",
       " 'actinium',\n",
       " 'actiniums',\n",
       " 'actionable',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'activation',\n",
       " 'activations',\n",
       " 'activator',\n",
       " 'activators',\n",
       " 'actively',\n",
       " 'activeness',\n",
       " 'activenesses',\n",
       " 'activewear',\n",
       " 'activism',\n",
       " 'activisms',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actresses',\n",
       " 'actual',\n",
       " 'actualities',\n",
       " 'actuality',\n",
       " 'actualization',\n",
       " 'actualizations',\n",
       " 'actualize',\n",
       " 'actualized',\n",
       " 'actualizes',\n",
       " 'actualizing',\n",
       " 'actually',\n",
       " 'actuals',\n",
       " 'actuarial',\n",
       " 'actuarially',\n",
       " 'actuaries',\n",
       " 'actuary',\n",
       " 'actuate',\n",
       " 'actuated',\n",
       " 'actuates',\n",
       " 'actuating',\n",
       " 'actuation',\n",
       " 'actuations',\n",
       " 'actuator',\n",
       " 'actuators',\n",
       " 'acuities',\n",
       " 'acuity',\n",
       " 'acumen',\n",
       " 'acumens',\n",
       " 'acupressure',\n",
       " 'acupressures',\n",
       " 'acupuncture',\n",
       " 'acupunctures',\n",
       " 'acupuncturist',\n",
       " 'acupuncturists',\n",
       " 'acutely',\n",
       " 'acuteness',\n",
       " 'acutenesses',\n",
       " 'acuter',\n",
       " 'acutest',\n",
       " 'acyclical',\n",
       " 'acyclovir',\n",
       " 'acyclovirs',\n",
       " 'adages',\n",
       " 'adagio',\n",
       " 'adagios',\n",
       " 'adamant',\n",
       " 'adamantly',\n",
       " 'adamants',\n",
       " 'adaptabilities',\n",
       " 'adaptability',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'adaptive',\n",
       " 'adaptor',\n",
       " 'adaptors',\n",
       " 'addable',\n",
       " 'addenda',\n",
       " 'addendum',\n",
       " 'addendums',\n",
       " 'addible',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'additive',\n",
       " 'additives',\n",
       " 'addressable',\n",
       " 'addressee',\n",
       " 'addressees',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'addressor',\n",
       " 'adduces',\n",
       " 'adducing',\n",
       " 'adenine',\n",
       " 'adenines',\n",
       " 'adenoid',\n",
       " 'adenoidal',\n",
       " 'adenoids',\n",
       " 'adeptly',\n",
       " 'adeptness',\n",
       " 'adeptnesses',\n",
       " 'adequacies',\n",
       " 'adequacy',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adequateness',\n",
       " 'adequatenesses',\n",
       " 'adherence',\n",
       " 'adherences',\n",
       " 'adherent',\n",
       " 'adherents',\n",
       " 'adhering',\n",
       " 'adhesion',\n",
       " 'adhesions',\n",
       " 'adhesive',\n",
       " 'adhesiveness',\n",
       " 'adhesivenesses',\n",
       " 'adhesives',\n",
       " 'adios',\n",
       " 'adipose',\n",
       " 'adjacencies',\n",
       " 'adjacency',\n",
       " 'adjacent',\n",
       " 'adjacently',\n",
       " 'adjectival',\n",
       " 'adjectivally',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjourning',\n",
       " 'adjournment',\n",
       " 'adjournments',\n",
       " 'adjudges',\n",
       " 'adjudging',\n",
       " 'adjudicate',\n",
       " 'adjudicated',\n",
       " 'adjudicates',\n",
       " 'adjudicating',\n",
       " 'adjudication',\n",
       " 'adjudications',\n",
       " 'adjudicative',\n",
       " 'adjudicator',\n",
       " 'adjudicators',\n",
       " 'adjudicatory',\n",
       " 'adjunctive',\n",
       " 'adjuration',\n",
       " 'adjurations',\n",
       " 'adjuring',\n",
       " 'adjustable',\n",
       " 'adjustables',\n",
       " 'adjusted',\n",
       " 'adjuster',\n",
       " 'adjusters',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjustor',\n",
       " 'adjustors',\n",
       " 'adjutant',\n",
       " 'adjutants',\n",
       " 'adjuvant',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administers',\n",
       " 'administrate',\n",
       " 'administrated',\n",
       " 'administrates',\n",
       " 'administrating',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administratively',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiral',\n",
       " 'admirals',\n",
       " 'admiralties',\n",
       " 'admiralty',\n",
       " 'admiration',\n",
       " 'admirations',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admiring',\n",
       " 'admiringly',\n",
       " 'admissibilities',\n",
       " 'admissibility',\n",
       " 'admissible',\n",
       " 'admissibly',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admittance',\n",
       " 'admittances',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admixes',\n",
       " 'admixing',\n",
       " 'admixture',\n",
       " 'admixtures',\n",
       " 'admonish',\n",
       " 'admonished',\n",
       " 'admonishes',\n",
       " 'admonishing',\n",
       " 'admonishment',\n",
       " 'admonishments',\n",
       " 'admonition',\n",
       " 'admonitions',\n",
       " 'admonitory',\n",
       " 'adobe',\n",
       " 'adobes',\n",
       " 'adolescence',\n",
       " 'adolescences',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adoptable',\n",
       " 'adopted',\n",
       " 'adopter',\n",
       " 'adopters',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptions',\n",
       " 'adoptive',\n",
       " 'adorable',\n",
       " 'adorableness',\n",
       " 'adorablenesses',\n",
       " 'adorably',\n",
       " 'adoration',\n",
       " 'adorations',\n",
       " 'adorer',\n",
       " 'adorers',\n",
       " 'adoring',\n",
       " 'adoringly',\n",
       " 'adorning',\n",
       " 'adornment',\n",
       " 'adornments',\n",
       " 'adrenal',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenalines',\n",
       " 'adrenalins',\n",
       " 'adrenals',\n",
       " 'adroitly',\n",
       " 'adroitness',\n",
       " 'adroitnesses',\n",
       " 'adsorbent',\n",
       " 'adsorbents',\n",
       " 'adsorbing',\n",
       " 'adsorption',\n",
       " 'adsorptions',\n",
       " 'adulate',\n",
       " 'adulated',\n",
       " 'adulates',\n",
       " 'adulating',\n",
       " 'adulation',\n",
       " 'adulations',\n",
       " 'adulator',\n",
       " 'adulators',\n",
       " 'adulatory',\n",
       " 'adulterant',\n",
       " 'adulterants',\n",
       " 'adulterate',\n",
       " 'adulterated',\n",
       " 'adulterates',\n",
       " 'adulterating',\n",
       " 'adulteration',\n",
       " 'adulterations',\n",
       " 'adulterer',\n",
       " 'adulterers',\n",
       " 'adulteress',\n",
       " 'adulteresses',\n",
       " 'adulteries',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adulthoods',\n",
       " 'adumbrate',\n",
       " 'adumbrated',\n",
       " 'adumbrates',\n",
       " 'adumbrating',\n",
       " 'adumbration',\n",
       " 'adumbrations',\n",
       " 'advancement',\n",
       " 'advancements',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantaged',\n",
       " 'advantageous',\n",
       " 'advantageously',\n",
       " 'advantages',\n",
       " 'advantaging',\n",
       " 'adventitious',\n",
       " 'adventitiously',\n",
       " 'adventure',\n",
       " 'adventured',\n",
       " 'adventurer',\n",
       " 'adventurers',\n",
       " 'adventures',\n",
       " 'adventuresome',\n",
       " 'adventuress',\n",
       " 'adventuresses',\n",
       " 'adventuring',\n",
       " 'adventurous',\n",
       " 'adventurously',\n",
       " 'adventurousness',\n",
       " 'adventurousnesses',\n",
       " 'adverbial',\n",
       " 'adverbially',\n",
       " 'adverbials',\n",
       " 'adversarial',\n",
       " 'adversaries',\n",
       " 'adversary',\n",
       " 'adversely',\n",
       " 'adverseness',\n",
       " 'adversenesses',\n",
       " 'adverser',\n",
       " 'adversest',\n",
       " 'adversities',\n",
       " 'adversity',\n",
       " 'adverted',\n",
       " 'adverting',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertiser',\n",
       " 'advertisers',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advertisings',\n",
       " 'advertize',\n",
       " 'advertized',\n",
       " 'advertizement',\n",
       " 'advertizements',\n",
       " 'advertizes',\n",
       " 'advertizing',\n",
       " 'advertorial',\n",
       " 'advertorials',\n",
       " 'advices',\n",
       " 'advisabilities',\n",
       " 'advisability',\n",
       " 'advisable',\n",
       " 'advisably',\n",
       " 'advisedly',\n",
       " 'advisement',\n",
       " 'advisements',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisories',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advocacies',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'aegises',\n",
       " 'aerated',\n",
       " 'aerating',\n",
       " 'aeration',\n",
       " 'aerations',\n",
       " 'aerator',\n",
       " 'aerators',\n",
       " 'aerial',\n",
       " 'aerialist',\n",
       " 'aerialists',\n",
       " 'aerially',\n",
       " 'aerials',\n",
       " 'aerier',\n",
       " 'aeriest',\n",
       " 'aerobatic',\n",
       " 'aerobatics',\n",
       " 'aerobic',\n",
       " 'aerobically',\n",
       " 'aerobics',\n",
       " 'aerodrome',\n",
       " 'aerodromes',\n",
       " 'aerodynamic',\n",
       " 'aerodynamically',\n",
       " 'aerodynamics',\n",
       " 'aeronautic',\n",
       " 'aeronautical',\n",
       " 'aeronautics',\n",
       " 'aeroplane',\n",
       " 'aeroplanes',\n",
       " 'aerosol',\n",
       " ...]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com = dicti[dicti['Syllables'] > 2]\n",
    "complex_words = [word.lower() for word in com.Word]\n",
    "complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e8a06d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d202b720",
   "metadata": {},
   "source": [
    "### Tokenizing the words and sentences using ntlk module "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a880b",
   "metadata": {},
   "source": [
    "### Cleaning Data using nltk stopwords and isalpha() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f00296",
   "metadata": {},
   "source": [
    "### Calculating Positive score, Negative score, Polarity score, Subjectivity score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4ec56a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(lstr):\n",
    "    token_word = {}\n",
    "    token_sent ={}\n",
    "    for i in range(len(lstr)):\n",
    "        token_word[i] = word_tokenize(lstr[i])\n",
    "        token_sent[i] = sent_tokenize(lstr[i])\n",
    "    #print(token_word)  \n",
    "    #print(token_sent[3])\n",
    "    clean_token_word = {}\n",
    "    clean_token_sent = {}\n",
    "    for i in range(len(token_word)):\n",
    "        clean_token_word[i] = [word for word in token_word[i] if word.lower() not in stop_words and word.isalpha() == True]\n",
    "        sents=[]\n",
    "        for j in token_sent[i]:\n",
    "            sent = \" \".join([wor for wor in word_tokenize(j) if wor.lower() not in stop_words and wor.isalpha() == True ])\n",
    "            sents.append(sent.strip())\n",
    "        clean_token_sent[i] = sents\n",
    "    #print(clean_token_sent[7])\n",
    "    #print(clean_token_word[7][:15])\n",
    "    pos_score = []\n",
    "    neg_score = []\n",
    "    for i in range(len(clean_token_word)):\n",
    "        pos_score.append(len([word for word in clean_token_word[i] if word in pos]))\n",
    "        neg_score.append(len([wor for wor in clean_token_word[i] if wor in neg]))\n",
    "    polarity_score = [((pos_score[i] - neg_score[i])/((pos_score[i] + neg_score[i])+0.000001)) for i in range(len(pos_score))]\n",
    "    subjectivity_score = [((pos_score[i] + neg_score[i])/((len(clean_token_word[i]))+0.000001)) for i in range(len(pos_score))]\n",
    "    return pos_score,neg_score,polarity_score,subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "249d8e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c0ed357ef04303a5a973f129c6789a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_score = {}\n",
    "negative_score = {}\n",
    "polarity_Score = {}\n",
    "Subjectivity_Score = {}\n",
    "for i in tqdm(list(text_dict['test'].keys())):\n",
    "    p,n,q,s = clean_words(text_dict['test'][i])\n",
    "    positive_score[i]=p\n",
    "    negative_score[i]=n\n",
    "    polarity_Score[i]=q\n",
    "    Subjectivity_Score[i]=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "df540f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 13, 3, 3, 13, 0, 2, 2, 1, 5, 2, 1, 2, 0, 3, 0, 4, 7, 4, 2, 5, 6, 4, 3, 13]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_score['12 Angry Men']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ecff6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syllapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e4abb",
   "metadata": {},
   "source": [
    "## Function to calculate FOG Index,Word count,Complex Word Count....        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0f11af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fog(document,i):\n",
    "    doc = nlp(document, disable=['tagger', 'ner', 'entity_linker', 'textcat', 'entitry_ruler'])\n",
    "    sen_list = list(doc.sents)\n",
    "    num_sen = len(clean_token_sent[i])\n",
    "    num_words = 0\n",
    "    num_complex_words = 0\n",
    "    num_syllable = 0\n",
    "    num_char = 0\n",
    "    for sen_obj in sen_list:\n",
    "        words_in_sen = [token.text for token in sen_obj if token.is_alpha]\n",
    "        num_words += len(words_in_sen)\n",
    "        num_complex  = 0\n",
    "        for word in words_in_sen:\n",
    "            num_char += len(word.strip())\n",
    "            if 'es' not in word and 'ed' not in word:\n",
    "                num_syl = syllapy.count(word.lower())\n",
    "                num_syllable += num_syl\n",
    "            else:\n",
    "                num_syl = syllapy.count(word.lower())-1\n",
    "                num_syllable += num_syl\n",
    "            if num_syl > 2:\n",
    "                num_complex += 1\n",
    "        num_complex_words += num_complex\n",
    "    \n",
    "    avg_words_per_sen = round((num_words / num_sen),4)\n",
    "    pern_comp_words = round((num_complex_words / num_words)*100,4)\n",
    "    fog = 0.4 * (avg_words_per_sen + (pern_comp_words*100))\n",
    "    fog = round(fog,4)\n",
    "    avg_word_length = round((num_char/num_words),4)\n",
    "    res = [avg_words_per_sen,pern_comp_words,fog,avg_words_per_sen,num_complex_words,num_words,num_syllable,avg_word_length]\n",
    "    return res;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e837973e",
   "metadata": {},
   "source": [
    "### Writing Columns of Output csv file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "326c0068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c976ced5af743b0ac9a67b2e785927f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "C:\\Users\\joshy\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "for a in tqdm(list(text_dict['test'].keys())):\n",
    "    token_word = {}\n",
    "    token_sent ={}\n",
    "    for i in range(len(text_dict['test'][a])):\n",
    "        token_word[i] = word_tokenize(text_dict['test'][a][i])\n",
    "        token_sent[i] = sent_tokenize(text_dict['test'][a][i])\n",
    "    #print(token_word)  \n",
    "    #print(token_sent[3])\n",
    "    clean_token_word = {}\n",
    "    clean_token_sent = {}\n",
    "    for i in range(len(token_word)):\n",
    "        clean_token_word[i] = [word for word in token_word[i] if word.lower() not in stop_words and word.isalpha() == True]\n",
    "        sents=[]\n",
    "        for j in token_sent[i]:\n",
    "            sent = \" \".join([wor for wor in word_tokenize(j) if wor.lower() not in stop_words and wor.isalpha() == True ])\n",
    "            sents.append(sent.strip())\n",
    "        clean_token_sent[i] = sents\n",
    "    #print(clean_token_sent)\n",
    "    #print(clean_token_word[7][:15])\n",
    "    result_data = []\n",
    "    for i in range(len(positive_score[a])):\n",
    "        result_dict={}\n",
    "        result = calculate_fog(\"\".join(clean_token_sent[i]),i)\n",
    "        keys = ['AVG SENTENCE LENGTH','PERCENTAGE OF COMPLEX WORDS','FOG INDEX','AVG NUMBER OF WORDS PER SENTENCE','COMPLEX WORD COUNT','WORD COUNT','SYLLABLE PER WORD','AVG WORD LENGTH']\n",
    "        for j in range(len(keys)):\n",
    "            result_dict[keys[j]] = result[j]\n",
    "        result_data.append(result_dict)\n",
    "    data = [i[:-4] for i in os.listdir(f\"C:/Users/joshy/Desktop/project/2_data/{a}\")]\n",
    "    dff = pd.DataFrame({'Users':data})\n",
    "    dff['POSITIVE SCORE'] = positive_score[a]\n",
    "    dff['NEGATIVE SCORE'] = negative_score[a]\n",
    "    dff['POLARITY SCORE'] = polarity_Score[a]\n",
    "    dff['SUBJECTIVITY SCORE'] = Subjectivity_Score[a]\n",
    "    output_index = ['AVG SENTENCE LENGTH','PERCENTAGE OF COMPLEX WORDS','FOG INDEX','AVG NUMBER OF WORDS PER SENTENCE','COMPLEX WORD COUNT','WORD COUNT','SYLLABLE PER WORD','AVG WORD LENGTH']\n",
    "    for i in range(len(output_index)):\n",
    "        key = output_index[i]\n",
    "        dff[key] = [j[key] for j in result_data]\n",
    "    #dff['Overall_impression'] = ['Positive' for i in dff['POSITIVE SCORE'] if dff['POSITIVE SCORE'] > dff['NEGATIVE SCORE'] else 'Negative']\n",
    "    dff.to_csv(f'C:/Users/joshy/Desktop/project/output/{a}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246223e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242d7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d3b53-6313-4506-998c-66292d137191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
